 
\documentclass[manuscript,screen=true]{acmart}

\usepackage[utf8]{inputenc}
%\usepackage{xspace}
\usepackage{balance}
\usepackage{amsmath,amsfonts,mathtools,amsthm}
\usepackage[noend]{algpseudocode}
\usepackage{algorithm}

\mathchardef\mhyphen="2D

\title{Brief Announcement: An Improved Lower Bound for Dynamic Balanced Graph Partitioning}


\author{Maciej Pacut}
\email{maciek.pacut@gmail.com}
\orcid{0000-0002-6379-1490}
\affiliation{%
  \institution{Faculty of Computer Science, University of Vienna}
  \country{Austria}
}


\author{Mahmoud Parham} 
\email{mahmoud.parham@univie.ac.at}
\orcid{0000-0002-6211-077X}
\affiliation{%
  \institution{Faculty of Computer Science, University of Vienna}
  \country{Austria}
}

\author{Stefan Schmid} 
\email{stefan_schmid@univie.ac.at}
\affiliation{%
  \institution{Faculty of Computer Science, University of Vienna}
  \country{Austria}
}

\copyrightyear{2020} 
\acmYear{2020} 
\setcopyright{acmlicensed}
\acmConference{PODC '20}{July 29-August 2, 2020}{Toronto, Canada}

\keywords{online algorithms, competitive analysis}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%&&
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%&&
%  our macros start
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%&&
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%&&

\newcommand{\OPT}{\mathit{OPT}}
\newcommand{\ALG}{ALG}
\newcommand{\OBRP}{BRP}
\newcommand{\PPOBRP}{PP-BRP}
\newcommand{\TAlg}{{\ensuremath{ALG_{k=3}}}} % we should change this name



\newtheorem{claim}{Claim}
\newtheorem{fact}{Fact}
\newtheorem{rem}{Remark}
\newtheorem{observation}{Observation}
\newtheorem{property}{Property}


\DeclarePairedDelimiter\pair{(}{)}
\DeclarePairedDelimiter\set{\{}{\}}

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

\newcommand\mahmoud[1]{\color{green}\textbf{\\ Mahmoud: #1}\\\color{black}}
\newcommand\stefan[1]{\color{blue}\textbf{\\ Stefan: #1}\color{black}}
\newcommand\maciek[1]{\color{brown}\textbf{\\ Maciek: #1}\color{black}}


\newcommand{\todo}[1]{\noindent\color{brown}{todo: #1}\color{black}}


\begin{document}


\begin{abstract}
  In the online Graph RePartitioning problem, we are given a sequence of pairwise communication requests between n nodes, revealed online.
  The objective is to service these requests by partitioning the nodes into $\ell$ clusters, each of size $k$, such that frequently communicating nodes are located in the same cluster.
  The partitioning can be updated by migrating nodes between clusters for a fixed cost.
  The goal is to jointly minimize the amount of inter-cluster communication and migration cost.

  So far, for this natural problem, the best known deterministic algorithm was $O(k^2\cdot \ell^2)$-competitive, and the best known lower bound was $\Omega(k)$ for the competitive ratio of any deterministic algorithm that used the reduction from the caching problem.
  In this paper, we provide the lower bound of $\Omega(k\cdot \ell)$.
  
  We also present the optimal algorithm for $k=3$.
  Finally, we provide a $O(k\cdot \ell)$-competitive algorithm for the scenario, where the perfect partition of input exists.
\end{abstract}
    
\maketitle
    
\renewcommand{\shortauthors}{M.~Pacut, M.~Parham, S.~Schmid}

\section{Introduction}

Main technical contribution of this paper is the lower bound $\Omega(k\cdot\ell)$ for the competitive ratio of any deterministic algorithm for Online Balanced Partition problem (cf. Section~\ref{sec:lowerbound}).
The best known lower bound so far was $\Omega(k)$ \cite{repartition-disc}
which involves only two cluster.


So far, the competitive ratio of the best known algorithm was the component-based algorithm with the ratio $O(k^2\cdot \ell^2)$ \cite{repartition-disc}.
We present an optimal algorithm for $k=3$ in Section~\ref{sec:k3}.
In Section~\ref{sec:ppl}, we present a $O(k\cdot \ell)$-competitive algorithm for the restricted scenario
where the communication graph (i.e., request sequence) admits a \emph{perfect partition} (i.e., a multi-way cut of cost zero) that is also an optimal configuration for the offline problem.
For this setting, the algorithm is optimal, as the lower bound utilized an input sequence that has a perfect partition.

\section{Related Work}

The problem was studied under resource augmentation \cite{repartition-disc}, and under stochastic assumptions of input\maciek{cite}.\maciek{cite other papers that cite DISC?}

The model is related to online
caching~\cite{SleTar85,FKLMSY91,McGSle91,AcChNo00}. In our
setting, requests can be served remotely, which is
reminiscent of caching models \emph{with
bypassing}~\cite{EpImLN11,EpImLN15,Irani02}.

The static offline version of~the~problem, called the
\emph{$\ell$-balanced graph partitioning problem} is 
NP-complete, and cannot even be approximated within any finite factor unless P
= NP~\cite{AndRae06}. The static
variant where $\ell = 2$ corresponds to the minimum bisection problem, which
is already NP-hard~\cite{GaJoSt76}, and 
the currently best approximation ratio is $O(\log n)$~\cite{SarVaz95,ArKaKa99,FeKrNi00,FeiKra02,KraFei06,Raec08}.




\section{Problem Definition}
\label{sec:problem-definition}

Formally, the online \emph{Balanced RePartitioning} problem (\OBRP{}) is defined as
follows. We are given a set of $n$ nodes,
initially arbitrarily partitioned into $\ell$~clusters,
each of size~$k$.
We say that nodes in $C \subset V$ are \emph{collocated}% in a partition $P$
if they are assigned to the same cluster.
%\maciek{We can ommit the formal definition: "I.e.,
%$\forall u,v \in C: \mathit{cluster} (u,P) = \mathit{cluster} (v,P)$.". %However, if we use the notion of cluster later, then TODO: define cluster}
%\maciek{We can ommit the formal definition: "I.e.,
%$\forall u,v \in C: \mathit{cluster} (u,P) = \mathit{cluster} (v,P)$.". However, if we use the notion of cluster later, then TODO: define cluster}
The input consists of a sequence of pairwise communication requests
$\sigma = (u_1,v_1),$ $(u_2,v_2),$ $(u_3,v_3), \ldots$,
where a pair $(u_t,v_t)$ indicates that nodes $u_t$ and $v_t$ exchange a fixed amount of data.
Before serving the request,
the online algorithm can re-partition,
i.e.,
it may (optionally) move some of the nodes into clusters different than their current assigned clusters.
Once the re-partition is executed,
we serve
the communication request between two  nodes at cost~0 if they are collocated,
or at cost~1 if they are located in different clusters.
The cost of migrating a node from one cluster to another
is~$\alpha \in \mathbb{Z}^+$.
For any algorithm $ALG$,
its cost,
denoted by $ALG(\sigma)$,
is the total cost of communications and
the cost of migrations performed by $ALG$ while serving the sequence $\sigma$.


\section{Recovering a Perfect Partition}	\label{sec:ppl}
%\subsection{Perfect Partition Model}\label{sec:perfectPartition}
%\maciek{Here introduce a restricted model of \PPOBRP{}, the restricted variant where the input sequence can be perfectly partitioned}
%\maciek{ every algorithm must colocate every communicating pair.
%	\mahmoud{updated!}}
We  focus on a restricted variant of  \OBRP{},
where the communication graph can be partitioned into $\ell$ clusters without any inter-cluster edges.
Moreover, we assume an optimal offline algorithm (OPT) moves to this \emph{perfect partition}
at the beginning and stays there permanently.
We refer this variant as \PPOBRP{}.
The task of an online algorithm for \PPOBRP{} is to "recover" (or learn) the perfect partition while not paying too much more than OPT.
This implies that on a request between any two non-collocated nodes,
any online algorithm must eventually collocate them,
as otherwise it not competitive under a sequence that repeats the same request arbitrarily many times.
Hence,
any competitive algorithm,
must at some point collocate all nodes of a  connected sub-graph of the communication graph.
We refer to this connected sub-graph as a \emph{component}.
An algorithm that always keeps a component collocated is \emph{component-respecting}.
%\maciek{Note that the algorithm from Section~\ref{sec:k3} is $O(\ell)$-competitive for the Perfect Partition Model, as during the first phase, a perfect partition of input exists.}

\subsection{An $O(k\cdot \ell)$-competitive Algorithm for Perfect Partition}
     
We assume OPT begins with the initial configuration
$P_I = I_1, \dots, I_{\ell}$ and moves to the final partition
$P_F = F_1, \dots, F_{\ell}$.
 The \emph{distance} of a configuration $P = C_1, \dots, C_{\ell}$ from the initial configuration is the number of nodes in $P$ that do not reside in their initial cluster.
    That is,
    $\mathit{dist}(P, P_I) := \sum_{j=1}^{\ell} | C_j \setminus I_j |$. 
In other words,
at least $\mathit{dist}(P, P_I)/2$ node swaps are required in order to reach the configuration $P$ from $P_I$.
Therefore,
$\OPT \geq \Delta:= dist(P_F, P_I) $.
 With each re-partitioning,
  PPL moves to a configuration that minimizes distance to the initial configuration $P_I$.
As a result,
ON never ends up in a configuration that is more than $\Delta$ away from $P_I$.
This invariant ensures that ON does not pay too much while reaching $P_F$.


\begin{algorithm}
    \renewcommand{\algorithmicrequire}{\textbf{Input:}}
    \renewcommand{\algorithmicensure}{\textbf{Output:}}
    \begin{algorithmic}[1]
        \Require 
        $k, \ell$,
        initial configuration $P_I$,
        sequence of  requests $\sigma_1, \dots, \sigma_N$ 
        \Ensure A final configuration $P_F$ 
        \State For each node $v$ create a singleton component $C_v$ and add it to $\mathcal{C}$
        \State{$P_0 := P_I$}
         \label{line:initcomponents}
        \For {each  request $\sigma_t=\{u,v\}, 1 \leq t \leq N$}
        \State Let $C_1 \ni u$ and $C_2 \ni v$ be the container components
        \If{$C_1 \neq C_2$}
        \State Unite the two components into a single component $C'$ and
        $\mathcal{C} = (\mathcal{C}\setminus\set{C_1, C_2}) \cup ~\set{C'}$ \label{line:mergecomponents}
%        \If{$\mathit{cluster}(C_1, P_{t-1}) \neq \mathit{cluster}(C_2, P_{t-1})$}
        \If{$\mathit{cluster}(C_1, P_{t-1}) \neq \mathit{cluster}(C_2, P_{t-1})$}
        \Comment{if not in the same cluster}
        \State $P_{t} = \mathit{re\mhyphen partition}(P_{t-1}, P_I, \mathcal{C}$) \label{line:rebalance} 
        \Comment{move to $P$ closest to $P_I$}
        \EndIf
        \EndIf
        \EndFor
    \end{algorithmic}
    \caption{Perfect Partition Learner (PPL)}
    \label{alg:ppl}
      \end{algorithm}
  
%      \maciek{``re-partition'' procedure name should indicate the fact that this is a specific repartition that is close to initial partition}
      We note that the $\mathit{re\mhyphen partition}$ at Line \ref{line:rebalance} replaces the current configuration $P$ with a (perfect) partition closest to $P_I$.
Hence it never moves to a configuration beyond distance $\Delta$.      
\begin{property} \label{prop:dist<OPT}
    Let $P$ be any configuration chosen by Algorithm \ref{alg:ppl} at Line $\ref{line:rebalance}$.
    Then, $\mathit{dist}(P,P_I) \leq \Delta$.
\end{property}

\begin{lemma}	\label{lemma:rebalancecost}
    The cost of re-partitioning at Line \ref{line:rebalance} is at most $2\cdot\OPT$.
\end{lemma}
\begin{proof}
    Consider the re-partitioning that transforms $P_{t-1}$ to $P_t$ upon the request $\sigma_t$.
    Let $M \subset V$ denote the set of nodes that migrate during this process.
	Let $M^-$ and $M^+$ denote the subset of nodes that (respectively)
    enter or leave their original cluster during the re-partitioning.    
    Then,
    $M = M^+ \cup M^-$.
    Since $|M^-|$ nodes are not in their original cluster before the re-partitioning (i.e., in $P_{t-1}$),
    the distance before the re-partitioning is $\mathit{dist}(P_{t-1},P_I) \geq | M^-|$.
    Analogously,
     the distance afterwards is $\mathit{dist}(P_{t},P_I) \geq | M^+|$.
    Thus,
    $|M| \leq \mathit{dist}(P_{t-1},P_I) + \mathit{dist}(P_{t},P_I)$.
    By Property \ref{prop:dist<OPT},
    $\mathit{dist}(P_{t-1},P_I) , \mathit{dist}(P_{t},P_I) \leq \Delta \leq \OPT$
    and thereby we have	
    $|M| \leq 2\cdot\OPT$.
\end{proof}

\begin{theorem}	\label{thm:upperbound}
    PPL reaches the final configuration $P_F$ and it is $(2\cdot k\cdot\ell)$-competitive.
\end{theorem}
\begin{proof}
      On each inter-cluster request,
     the algorithm enumerates all $\ell$-way partitions of components
     that are in the same (closest) distance of $P_I$.
     That is, 
     once it reaches a configuration $P$ at distance $\Delta = \mathit{dist} (P, P_I)$,
     it does not move to a configuration
     $P', \mathit{dist} (P', P_I) > \Delta$,
     before it enumerates all configurations at distance $\Delta$.
     Therefore,
     PPL eventually reaches $\Delta=\OPT$ and the configuration $P_F$.
%    including the request that completes revealing of all components that are collocated in $P_F$.
    There are at most $(k-1)\cdot\ell < k\cdot\ell $ calls   to $\mathit{re\mhyphen partition}$
     (i.e., the number of internal edges in $P_F$).
    By Lemma \ref{lemma:rebalancecost},
    each re-partition costs at most $2\cdot\OPT$.
    The total cost is therefore at most $2\cdot\OPT\cdot k\cdot\ell$ which implies the competitive ratio.
%    \mahmoud{This is the cost of moving and the cost of remote comm. is not counted.
%    	So it is 4-competitive (?)}
 \end{proof}

\section{Lower bound} %$\Omega(k\cdot \ell)$ for Competitive Ratio of Any Deterministic Algorithm}
\label{sec:lowerbound}

In this section we show a lower bound of $\Omega(k \cdot \ell)$ for \OBRP{}.
The constructed input sequence allows OPT to move to a perfect partition, and hence
the construction also constitutes a lower bound for \PPOBRP{}.
This complements an upper bound of $O(k \cdot \ell)$
for \PPOBRP{} that we present in Section \ref{sec:ppl}.

\begin{theorem}
	The competitive ratio of any deterministic algorithm for \OBRP{} is in $\Omega(k\cdot \ell)$.
\end{theorem}

\begin{proof}
	We construct an instance of the problem with $\ell$ clusters 
	$\set{ S_1, S_2,\dots , S_{\ell}}, |S_i|  = k$.
	Let $I(C)$ denote the cluster where nodes in a component $C$ are located initially.
%	\maciek{So far components were not introduced; the best place to introduce these would be around the definition of \PPOBRP}.
	Fix any online algorithm \ALG{}.
	We construct the input sequence of requests for \ALG{} as follows.
	First,
	we issue $k-2$ (internal) requests so that \ALG{} can form a component of $k-1$
	nodes on the cluster $S_1$.
	Recall that internal requests does not incur any cost for \ALG{}.
	If \ALG{} at any point splits a component
	(i.e., spreads its nodes over two or more clusters),
	then we continue to issue requests between non-collocated nodes of the component until \ALG{} collocates the nodes of the component.
	If \ALG{} never collocates them then it is not competitive.
	
	Let $x_0$  be the only single node left on $S_1$ and  $y_0 \in S_2$ be any single node on $S_2$.
	Next,
	we issue the request between $x_0$ and $y_0$.
	Since this is an external request,
	\ALG{} joins them into one component and collocates them in some cluster other than $S_1$.
	For this,
	\ALG{} moves to a new configuration
	that replaces $x_0$ and $y_0$ with two other single nodes $x_1$ and $y_1$ respectively.
	
	Next,
	we issue a request between $x_1$ and the largest component $C$ s.t.~$I(C) = I(x_1)$.
	\ALG{} must collocate $x_1$ and $C$ on some cluster other than $S_1$ and
	consequently replaces $x_1$ with some other (single) node $x_2$.
	We repeat issuing requests between the single node $x_i$ on $S_1$ and the largest component $C'$ s.t.~$I(C')=I(x_i)$,
	until there are only two single nodes left that  originate from the same cluster.
	I.e.,
	two single nodes $x^*, y^*,I(x^*) = I(y^*)$ s.t.~for any other pair of single nodes
	$x'$ and $y'$,
	we have $I(x') \neq I(y')$.
	At this point there are at most $\ell+1$ single nodes left,
	otherwise there would be more pairs of single nodes that were initially in the same cluster.
	
	Given this sequence of requests,
	the optimal strategy is to migrate $\set{x_0,y_0}$ to the cluster $I(x^*)$ by
	swapping $\set{x_0,y_0}$ with $\set{x^*,y^*}$.
	Hence,
	OPT pays for $4$ node migrations and
	\ALG{} incurs at least one migration for each node in the sequence $X := x_0, x_1,\dots$.
	We exclude at most $(k-1) + ( \ell+1)$ nodes out of $k \cdot \ell$ nodes,
	therefore $|X| \geq k \cdot \ell - k - \ell \in \Omega(k\cdot\ell)$.
\end{proof}

\section{Corollary and Future Directions}

The gap between upper and lower bound is still substantial, as the best known algorithm is the component-based algorithm of   \cite{repartition-disc} with competitive ratio $O(k^2\cdot\ell^2)$.


\bibliographystyle{ACM-Reference-Format}
\bibliography{references}  

\begin{appendix}

\section{Todos}

\todo{ACM format for review? With line numbers etc.}

\todo{Make ORCID visible in ACM style: "Right now we do not typeset ORCIDs" (Source: ACM Style Docs)}

\todo{Include e-mails}

\todo{Check ACM package whitelist}

\todo{Replace package algorithmpseudocode, it is not whitelisted https://www.acm.org/publications/taps/whitelist-of-latex-packages}

\todo{Make an ACM account for the submission}

\todo{Sum up all the steps needed for the submission}

\todo{ACM keywords are mandatory}

\todo{CCS concepts are mandatory}

\todo{Check grammar}

\todo{Font for OPT, ALG, DET, dist etc}

	\section{Ommited results}
	\begin{enumerate}
		 \item The lower bound of $\Omega(\ell)$ for the scenario with at most $(1/3-1/k)$-augmentation
		 \item Costly cascade example (it is easy to present $k^2$ and $k\cdot \sqrt{k}$ (with different approach), and then we can combine these to obtain $k^3$)
		 \item $k$-competitive algorithm for the ring communication pattern
		 \item $O(\ell)$-competitive algorithm for $k=4$ and $k=5$
  \end{enumerate}
  


  \section{An Optimal Algorithm for $k=3$ (most likely wrong)}

  In this section we provide an optimal algorithm for the case $k=3$.
  
  We define the algorithm \TAlg{} in the following way.
  \TAlg{} maintains components for each node.
  Intially, each node is in its own singleton component.
  For each pair of nodes \TAlg{} maintains a counter, initiated $0$, and upon receiving a request to this pair while its nodes are located on different servers, it increases the counter by $1$.
  If a counter for a pair $(u,v)$ reaches $\alpha$, \TAlg{} merges the components of $u$ and $v$, and moves to the closest partition, where it each component has all of its nodes in one server.
  If no such partition exists, \TAlg{} resets all components to singletons and all counters to $0$.

  %\maciek{Shouldn't we think about whole component cuts instead of single edge? Hmm. NO!}

  We say that \TAlg is \emph{component respecting}, i.e., it maintains the invariant that nodes of each component are located at the same server.
  Observe that this implies that \TAlg never increases any counter above $\alpha$.
  
  \begin{lemma}
    \label{lem:1req}
    A single repartition incurs the cost at most $3\cdot\alpha$ for \TAlg.
  \end{lemma}
  
  \begin{proof}
    If no partition of \TAlg's components exist, then it performs no repartition, and serves the request remotely, incurring the cost $1$.
    Hence, in the following we bound the cost of moving to component-respecting partition.
  
    We distinguish between three types of clusters: $C_1, C_2, C_3$,
    which we define as follows.
    A cluster of type $C_1$ the cluster contains $3$ singleton components (this is also the initial configuration of any cluster).
    A cluster of type $C_2$  contains one component of size $2$ and one component of size $1$.
    Finally, a cluster of type $C_3$  contains one component of size $3$.
    
      Consider a request $(u, v)$ and let $U, V$ be clusters of these nodes.
      If $U=V$, then the request does not require a reconfiguration and GREEDY incurs no cost.
      Otherwise, we consider cases upon the type of clusters $U$ and $V$.
      Note that this is impossible that either $U$ or $V$ is $C_3$ as otherwise we encounter a component of size $4$ and this would contradict the case assumption that the component-respecting partition exists.
      If either $U$ or $V$ is $C_1$, then either cluster can fit the merged component, and the rebalance is local within $U$ and $V$, for the cost of at most $3$ migrations.
    
      Finally, we consider the case where both $U$ and $V$ are $C_2$. Note that $(u,v)$ cannot both belong to a component of size $2$, as this would mean that \TAlg{} has the component of size $4$, a contradiction with the case assumption that the component-respecting partition exists. 
      If either $u$ or $v$ belongs to a component of size $2$ then it suffices to exchange components of size $1$ between $U$ and $V$.
      Finally, if $u$ and $v$ belong to components of size $1$, then we must place them in a cluster different from $U$ and $V$.
      Note that in such case, a $C_1$-type cluster $W$ exists, as otherwise the input graph would not have a perfect partition. In this case GREEDY exchanges the nodes $u$ and $v$ with any two nodes of $W$, for the total cost of $2\cdot \alpha$.
  \end{proof}
  
  
  \begin{theorem}
    \TAlg{} is $O(\ell)$-competitive.
  \end{theorem}
  \begin{proof}
    Fix a phase of \TAlg, and consider the state of its counters at the end of it.

    Let $A^I$ be the cost of (extra-cluster) communication incurred in this phase by \TAlg between pairs that belonged to the single component at the end of the phase.
    Let $A^E$ be the cost of (extra-cluster) communication incurred in this phase between the nodes that belong to different components throughout this phase.
    Let $A^M$ be the cost of migrations performed by \TAlg in this phase.

    We say that the pair $(u, v)$ is \emph{saturated}, if the counter has value $\alpha$, and \emph{unsaturated} otherwise.
    

    During a single phase, at most $2\cdot \ell$ component merge operations are performed.
    Exceeding this number would mean that a component of size $4$ would emerge, a contradiction.
    Together with Lemma~\ref{lem:1req}, this gives us $A^M \leq 6\cdot\alpha\cdot\ell$.
    
    Now we bound $A^I$.
    Each component of size $3$ contributes at most $(3\cdot \alpha - 1)$ to $A^I$, as at most $2$ of its pairs are saturated and contribute $\alpha$ each, and the unsaturated pair contributes at most $\alpha-1$.
    Each of $\ell$ clusters of \TAlg contain at most one component of size $3$ (other cluster configurations contribute less: $3$ singletons contribute $0$ and a component of size $2$ contributes at most $\alpha$ to $A^I$), and in total, $A^I \leq \ell \cdot (3\cdot \alpha-1)$.

    We bound $A^E$ by $k^2 \cdot (\alpha - 1)$, as no more than $k^2$ pairs are unsaturated, and each of them contributes at most $\alpha -1$.

    In total, the cost of \TAlg is at most $A^I + A^E + A^M$ during the phase.

    Now we lower bound the cost of $\OPT$.
  \end{proof}
  

  \section{An old section about $k=3$}

  \label{sec:k3}
  In this section,
  we give an alternative algorithm for the special case of $k=3$.
  The algorithm does not  improve upon PPL (asymptotically),
  but we will use it in Section \ref{sec:generalModel} for the same special case in the general model.
  
  \maciek{We must introduce phases in the description of this algorithm. If no PP exists, the algorithm resets its components.}
  
  Let \emph{GREEDY} be the algorithm that on each inter-cluster request
   moves to a perfect partition
  % \maciek{of input}
  closest to the current partition,
  i.e.,
  reachable in minimum number of node swaps (ties broken arbitrarily).
  
  \begin{lemma} \label{lemma:k=3}
    Every re-balancing cost of GREEDY for $k=3$ is $O(1)$.
    %\maciek{GREEDY = find the cheapest (closest to the current) feasible partition}
    \maciek{We need to add to the assumption that the input has a perfect partition
    \mahmoud{the section now is only about PP model}}
    \label{rebalancing-cost}
  \end{lemma}
  
  \begin{proof} 
  % \maciek{Note: we consider a cost of cheapest feasible rebalancing after insertion of one edge. This in contrast to bounding the distance between any two reconfigurations (this theorem does not bound the latter).}
  
    \maciek{We probably should start with something along: Note that the assumption of perfect partition means that there is no component of size 4. Then refer to it (twice) by some short ref.}
    
    We distinguish among three configuration types of any algorithm's cluster: $C_1, C_2, C_3$, which we define as follows. In $C_1$ the cluster contains $3$ singleton components (this is also the initial configuration of any cluster). In $C_2$ it contains one component of size $2$ and one component of size $1$. Finally, in $C_3$ it contains one component of size $3$.
  
    Consider a request $(u, v)$ and let $U, V$ be clusters of these nodes.
    If $U=V$, then the request does not require a reconfiguration and GREEDY incurs no cost.
    Otherwise, we consider cases upon the type of clusters $U$ and $V$.
    Note that this is impossible that either $U$ or $V$ is $C_3$ as otherwise we encounter a component of size $4$ and this would contradict the existence of the perfect partition of the input.
    If either $U$ or $V$ is $C_1$, then either cluster can fit the merged component, and the rebalance is local within $U$ and $V$, for the cost of at most $3$ migrations.
  
    Finally, we consider the case where both $U$ and $V$ are $C_2$. Note that $(u,v)$ cannot both belong to a component of size $2$, as this would mean that an input sequence includes the component of size $4$, a contradiction. 
    If either $u$ or $v$ belongs to a component of size $2$ then it suffices to exchange components of size $1$ between $U$ and $V$.
    Finally, if $u$ and $v$ belong to components of size $1$, then we must place them in a cluster different from $U$ and $V$.
    Note that in such case, a $C_1$-type cluster $W$ exists, as otherwise the input graph would not have a perfect partition. In this case GREEDY exchanges the nodes $u$ and $v$ with any two nodes of $W$, for the total cost of $2\cdot \alpha$.
  \end{proof}
  
    
  \begin{theorem}
    Algorithm \emph{GREEDY} is $O(\ell)$-competitive when $k=3$.
    \maciek{Assumming the perfect partition of input sequence
    \mahmoud{the section now is only about PP model}}
  \end{theorem}
  
  \begin{proof}
    The adversary issues at most $3\ell$ requests, as otherwise the perfect partition would not exist.
    Each request triggers at most one re-balancing in \emph{GREEDY}
    which costs $O(1)$ by Theorem~\ref{rebalancing-cost}.
    Then,
    the total cost of any algorithm is $O(\ell)$.
  \end{proof}
  
  \section{Arbitrary Communication Graph} \label{sec:generalModel}
  
  We leverage the simple algorithm \emph{GREEDY} for $k=3$
  towards an algorithm for the general problem
  where the communication graph is not restricted.
  Note that in the general model,
  an optimal partition is not a necessarily a perfect partition.
  We divide the sequence of requests into phases.
  A phase terminates when there is no perfect partition of components.
  We apply requests to \emph{GREEDY} as before. 
  Once the current phase terminates,
  we reset all components by removing (forgetting) all revealed edges,
  and then we proceed to the next phase.
  
  \begin{theorem} \label{cor:k=3}
    There exists $O(\ell)$-competitive algorithm for the general online problem when $k=3$. 
  \end{theorem}
  \begin{proof}
    \maciek{TODO: this proof is incomplete!}
    Consider any phase and assume it terminates upon arrival of some request $r$.
    By Lemma  \ref{lemma:k=3},
    \emph{GREEDY} pays $O(\ell)$ during the phase.
    If OPT stays in the same configuration throughout the phase,
    regardless of its partition at the beginning of the phase,        
    it incurs remote communication cost for at least one request $r'$ (possibly $r'=r$) by the end of the phase.
    Else,
    OPT incurs the cost of moving to new partitions.
    In any case,
    OPT pays at least one during the phase and 
    the competitive ratio is $O(\ell)$.
  \end{proof}
  
  

\end{appendix}

\end{document}
