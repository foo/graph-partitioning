 
\documentclass[manuscript,screen=true]{acmart}

\usepackage[utf8]{inputenc}
\usepackage{xspace}
\usepackage{balance}
\usepackage{amsmath,amssymb,amsfonts,mathtools,amsthm}
\usepackage[noend]{algpseudocode}
\usepackage{algorithm}



\title{Brief Announcement: An Improved Lower Bound for Dynamic Graph Partitioning}


\author{Maciej Pacut}
%\orcid{0000-0002-6379-1490}
\affiliation{%
  \department{Faculty of Computer Science}
  \institution{University of Vienna}
  \country{Austria}
}

\author{Mahmoud Parham} 
\affiliation{%
  \department{Faculty of Computer Science}
  \institution{University of Vienna}
  \country{Austria}
}

\author{Stefan Schmid} 
\affiliation{%
  \department{Faculty of Computer Science}
  \institution{University of Vienna}
  \country{Austria}
}

\copyrightyear{2020} 
\acmYear{2020} 
\setcopyright{acmlicensed}
\acmConference{PODC '20}{July 29-August 2, 2020}{Toronto, Canada}

\keywords{online algorithms, competitive analysis, etc}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%&&
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%&&
%  our macros start
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%&&
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%&&



\newtheorem{claim}{Claim}
\newtheorem{fact}{Fact}
\newtheorem{rem}{Remark}
\newtheorem{observation}{Observation}
\newtheorem{property}{Property}


\DeclarePairedDelimiter\pair{(}{)}
\DeclarePairedDelimiter\set{\{}{\}}

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

\newcommand\mahmoud[1]{\color{green}\textbf{\\ Mahmoud: #1}\\\color{black}}
\newcommand\stefan[1]{\color{blue}\textbf{\\ Stefan: #1}\color{black}}
\newcommand\maciek[1]{\color{brown}\textbf{\\ Maciek: #1}\color{black}}


\newcommand{\todo}[1]{\noindent\color{brown}{todo: #1}\color{black}}


\begin{document}


\begin{abstract}
    Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
\end{abstract}
    
\maketitle
    
\renewcommand{\shortauthors}{M.~Pacut, M.~Parham, S.~Schmid}

\section{Introduction}

Main technical contribution of this paper is $\Omega(k\ell)$ lower bound for the competitive ratio of any deterministic algorithm for Online Balanced Partition problem.
The best known lower bound so far was $\Omega(k)$ \cite{repartition-disc}.


Additionally, we contribute to search for the optimal algorithm by presenting $O(k\ell)$-competitive algorithm for the special case, where the perfect partition of the input graph is assumed, and every algorithm must colocate every communicating pair.
Note that our $\Omega(k\ell)$ lower bound uses a perfect partition input graph and colocates communicating pairs, and hence for this scenario, our results are tight.
\maciek{Also, it is easy to construct the adversary that forces collocation of requested nodes}

\section{Related Work}

In this paper we study the Online Balanced Partitioning problem (formally presented in Section~\ref{sec:problem-definition}).
The static offline version of~the~problem, i.e., a problem variant where
migration is not allowed, where all requests are known in advance, and where
the goal is to find an assignment of $n$ nodes to $\ell$~physical machines, each of~capacity $n/\ell$, is known as the
\emph{$\ell$-balanced graph partitioning problem}. The problem is 
NP-complete, and cannot even be approximated within any finite factor unless P
= NP~\cite{AndRae06}.  The static
variant where $\ell = 2$ corresponds to the minimum bisection problem, which
is already NP-hard~\cite{GaJoSt76}, and 
the currently best approximation ratio is $O(\log n)$~\cite{SarVaz95,ArKaKa99,FeKrNi00,FeiKra02,KraFei06,Raec08}.
The inapproximability of the static variant for general values of $\ell$
motivated research on the bicriteria variant, which can be seen as the offline
counterpart of our capacity augmentation approach. Here, the~goal
is~to~compute a~graph partitioning into $\ell$ components of~size at most~$k$ (where $k > n/\ell$) and the cost of the cut is compared to the optimal (non-augmented)
solution where all components are of a~size at most $n/k$. The variant where
$n \geq 2 \cdot k \cdot \ell$ was considered in
\cite{LeMaTr90,SimTen97,EvNaRS00,EvNaRS99,KrNaSc09}. So far, the~best result~is~an~$O(\!\sqrt{\log n \cdot \log \ell})$-approximation algorithm~\cite{KrNaSc09}.

Our model is related to online
caching~\cite{SleTar85,FKLMSY91,McGSle91,AcChNo00}, sometimes also referred to
as online caching, where requests for data items (nodes) arrive over time and
need to be served from a cache of finite capacity, and where the number of
cache misses must be minimized. Classic problem variants usually boil down to
finding a smart eviction strategy, such as Least Recently Used (LRU)~\cite{SleTar85}. In our
setting, requests can be served remotely (i.e.,~without fetching the
corresponding nodes to a single physical machine). In this light, our model is more
reminiscent of caching models \emph{with
bypassing}~\cite{EpImLN11,EpImLN15,Irani02}. As a~side result, we show that our problem is
capable of emulating online caching.
A major difference between  these problems is that in the caching problems, each request involves a~single element of the universe, while in our model \emph{both} endpoints of a communication request are subject to~optimization.

\section{Practical Motivation}


Distributed cloud applications, including batch processing
applications such as MapReduce, streaming applications such as Apache Flink or
Apache Spark, and scale-out databases and key-value stores such as Cassandra,
generate a~significant amount of network traffic and a~considerable fraction
of their runtime is due to network activity~\cite{MogPop12}. For example,
traces of jobs from a Facebook data center reveal that network transfers on
average account for 33\% of the execution time~\cite{orchestra}. In such
applications, it is desirable that frequently communicating virtual machines
are \emph{collocated}, i.e., mapped to the same physical server: 
communication across the network (i.e., inter-server communication) induces
network load and latency. However, migrating virtual machines between servers
also comes at a price: the state transfer is bandwidth intensive, and may even
lead to short service interruptions. Therefore the goal is to design online
algorithms that find a good trade-off between the inter-server communication
cost and the migration cost.


\vspace{1cm}

We study virtual network embeddings in the scenario where virtual machines can be migrated during runtime to another physical machine.
The possibility of migration allows reacting to unpredictable communication patterns.
For example, if some distant nodes communicate often, it is vital to reduce their distance to save network bandwidth.
The objective is to~minimize the total network bandwidth used for communication and for migration.


We assume that the communication patterns are not known in advance to our algorithm.
We measure the~quality of~presented algorithmic solutions by competitive analysis~\cite{borodin-book}, which is well-suited for problems that are online by their nature.
In the competitive analysis, the goal is to~optimize \emph{the competitive ratio} of a given online algorithm: the ratio of its cost to the cost of~an~optimal offline algorithm that knows the whole input sequence in advance.

We assume that the physical substrate network is a~tree of height one.
That is, every physical machine (leaf) is connected directly to the root (that has no hosting capabilities).
A single physical machine hosts a fixed number of virtual machines.
The model restricted to such networks becomes a variant of online graph clustering.
That is, we are given a~set of~$n$ nodes (virtual machines) with time-varying pairwise
communication patterns, which have to be partitioned into~$\ell$~physical machines, each of
capacity $k=n/\ell$.

Intuitively, we would like to minimize inter-machine
interactions by mapping frequently communicating nodes to the same physical machine
Since communication patterns change over time, the~nodes should be \emph{repartitioned}, in
an online manner, by \emph{migrating} them between physical machines.
The~objective is to minimize the weighted sum of inter-machine communication and repartitioning costs.
The former is defined as the number of communication requests between nodes placed at distinct physical machines, and the latter as the number of migrations.


The possibility to perform a migration uncovers algorithmic challenges:
\begin{itemize}

\item \emph{Serve remotely or migrate?} For a brief communication
pattern, it may not be worthwhile to collocate the nodes: the migration cost might
be too large in comparison to~communication costs.

\item \emph{Where to migrate, and what?}
If an algorithm decides to collocate nodes $x$ and~$y$, the~question becomes
how. Should $x$ be migrated to the physical machine holding $y$, $y$ to the one holding
$x$, or should both nodes be migrated to a new machine?

\item \emph{Which nodes to evict?}
The space of the desired destination physical machine may not be sufficient. In
this case, the~algorithm needs to decide which nodes to ``evict'' (migrate to
other machines), to free up space.

\end{itemize}


\section{Problem Definition}
\label{sec:problem-definition}

Formally, the online \emph{Balanced RePartitioning} problem (BRP) is defined as
follows. There is a set of $n$ nodes, initially distributed arbitrarily
across $\ell$~clusters, each of size~$k$. We call two nodes~$u,v\in V$
\emph{collocated} if they are in the same cluster.

An input to the problem is a sequence of communication requests $\sigma =
(u_1,v_1),$ $(u_2,v_2),$ $(u_3,v_3), \ldots$, where pair $(u_t,v_t)$ means that
the nodes $u_t,v_t$ exchange a fixed amount of data.  At any time~$t$, an online algorithm needs to serve the~communication
request~$(u_t,v_t)$. Right before serving the request, the online algorithm
can repartition the nodes into new clusters. We assume that
a~communication request between two collocated nodes costs 0. The cost of a~communication request between two nodes located in different clusters is
normalized to~1, and the cost of migrating a node from one cluster to another
is~$\alpha \geq 1$, where $\alpha$ is a parameter (an~integer). For any
algorithm $ALG$, we denote its total cost (consisting of communication plus
migration costs) on sequence $\sigma$ by $ALG(\sigma)$.

\section{Lower bound $\Omega(k\cdot \ell)$ for Competitive Ratio of Any Deterministic Algorithm}


In this section we consider the Online Balanced Partition problem.
We show a lower bound of $\Omega(k \cdot \ell)$ that uses an input that has a perfect partition.
Therefore, this result is a lower bound for the general Online Balanced Partition problem, as well as a lower bound for Online Balanced Partition with perfect partition.
The latter complements an upper bound $O(k \cdot \ell)$ for Online Balanced Partition with perfect partition that we present in Section \ref{sec:upperbound}.

\begin{theorem}
  The competitive ratio of any deterministic algorithm for Online Balanced Partition is $\Omega(k\cdot \ell)$.
\end{theorem}

\begin{proof}
\mahmoud{A simpler proof but still not fully rigorous. E.g., what if ALG collocates on $S_1$? Easy technicalities most likely.}
We construct an instance of the problem with $\ell$ clusters 
$\set{ S_1, S_2,\dots , S_{\ell}}, |S_i|  = k$.
Let $I(C)$ denote the cluster where nodes in a component $C$ are located initially.
Consider any online algorithm ALG.
We construct the input sequence of requests for ALG as follows.
First,
we issue $k-2$ (internal) requests so that ALG form a component of $k-1$
nodes on clusters $S_1$.
Note that this does not cost ALG.
Let $x_0$  be the only single nodes left on $S_1$ and  $y_0 \in S_2$ be any single node on $S_2$.
Next,
we issue the request between $x_0$ and $y_0$.
Since this is an external request,
ALG joins them into one component and collocates them in some cluster other than $S_1$.
For this,
ALG moves to a new configuration that replaces $x_0$ and $y_0$ with two other single nodes $x_1$ and $y_1$ respectively.
Next,
we issue a request between $x_1$ and the largest component $C$ s.t.~$I(C) = I(x_1)$.
ALG must collocate $x_1$ and $C$ on some cluster other than $S_1$ and
consequently replaces $x_1$.
We repeat issuing requests between the single node $x_i$ on $S_1$ and the largest component $C'$ s.t.~$I(C')=I(x_i)$,
 until there are only two single nodes left that  originate from the same cluster.
I.e.,
two single nodes $x^*, y^*,I(x^*) = I(y^*)$
that constitute the last pair of such nodes.
At this point there are at most $\ell+1$ single nodes left
since there must be at least two nodes with the same initial cluster in any subset of $\ell+1$
nodes.
Given this sequence of requests,
the optimal strategy is to migrate $\set{x_0,y_0}$ to the cluster $I(x^*)$ by
 swapping $x_0$ and $y_0$ with $x^*$ and $y^*$ respectively.
Hence,
OPT pays $4$ for node migrations and
ALG pays at least one for each node in the sequence $X := x_0, x_1,\dots$.
We exclude at most $(k-1) + ( \ell+1)$ nodes out of $k.\ell$ nodes,
therefore $|X| \geq k.\ell - k - \ell \in \Omega(k.\ell)$.
\end{proof}

\section{Perfect Partition Learner Algorithm}
    
     
Let $P_I = I_1, \dots, I_{\ell}$ denote the initial partition with which both ON and OPT begin and
$P_F = F_1, \dots, F_{\ell}$ the final partition.
\begin{definition}	\label{def:dist}
    The \emph{distance} of a partition $P = C_1, \dots, C_{\ell}$ is the number of nodes in $P$ that do not reside in their initial cluster.
    That is,
    $dist(P, P_I) = \sum_{j=1}^{\ell} | C_j \setminus I_j |$. 
\end{definition}
\maciek{We should figure out a better name than "distance". We usually apply two arguments to distance. Examples of names that can be applied to only one configuration as a parameter: radius, span, stretch, spread, width. Also: difference, disparity, distinction, alternation}

In other words,
at least $dist(P, P_I)/2$ node swaps are required in order to reach the partition $P$ from $P_I$.
Therefore,
$OPT \geq \Delta:= dist(P_F, P_I) $.
We devise an online algorithm that mimics OPT by minimizing the distance to the initial partition $P_I$ with each re-partitioning.
As a result,
ON never ends up in a partition that is further away from $P_I$ than $\Delta$.
This invariant ensures that ON does not pay too much while reaching $P_F$.

\begin{algorithm}
    \renewcommand{\algorithmicrequire}{\textbf{Input:}}
    \renewcommand{\algorithmicensure}{\textbf{Output:}}
    \begin{algorithmic}[1]
        \Require 
        $k, \ell$,
        initial partition $P_I$,
        sequence of  edges $\sigma_1, \dots, \sigma_N$ 
        \Ensure Final partition $P_F$ 
        \State for each node $v$ create a singleton component $C_v$ and add it to $\mathcal{C}$ \label{line:initcomponents}
        \State on communication request $\sigma_t=\{u,v\}$:
        \State Let $C_1 \ni u$ and $C_2 \ni v$ be the container components
        \If{$C_1 \neq C_2$}
        \State unite the two components into a single component $C'$ and
        $\mathcal{C} = (\mathcal{C}\setminus\set{C_1, C_2}) \cup ~\set{C'}$ \label{line:mergecomponents}
        \If{cluster$(C_1) \neq$ cluster$(C_2)$}		
        \State \textit{re-partition($k, \ell, P_I, \mathcal{C}$)} \label{line:rebalance} 
        \EndIf
        \EndIf
    \end{algorithmic}
    \caption{Perfect Partition Learner}
    \label{alg:ppl}
      \end{algorithm}

      \maciek{``re-partition'' procedure name should indicate the fact that this is a specific repartition that is close to initial configuration}

\mahmoud{address the \textit{re-partition()}}

\begin{property} \label{prop:dist<OPT}
    Let $P$ be any partition chosen by Algorithm \ref{alg:ppl} at Line $\ref{line:rebalance}$.
    Then, $dist(P,P_I) \leq \Delta$.
\end{property}

\begin{lemma}	\label{lemma:rebalancecost}
    The cost of re-partitioning at Line \ref{line:rebalance} is at most $2.OPT$.
\end{lemma}
\begin{proof}
    Consider the re-partitioning that transforms $P_{t-1}$ to $P_t$ upon the request $\sigma_t$.
    Let $M \subset V$ denote the set of nodes that are migrated during this process.
    We have $M = M^+ \cup M^- \cup M^\circ$,
    where $M^-$ ($M^+$) denotes the subset of nodes that
    enter (leave) their original cluster during the re-partitioning,
    and $M^\circ$ denotes the set of remaining nodes in $M$.
    Since $|M^- \cup M^\circ|$ nodes are not in their original cluster before the re-partitioning,
    by Definition \ref{def:dist},
    the distance before the re-partitioning is $dist(P_{t-1}) \geq | M^- \cup M^\circ |$.
    Analogously,
     the distance afterwards is $dist(P_{t}) \geq | M^+ \cup M^\circ |$.
    Thus,
    $|M| \leq dist(P_{t-1}) + dist(P_{t})$.
    By Property \ref{prop:dist<OPT},
    $dist(P_{t-1}) , dist(P_{t}) \leq \Delta \leq OPT$
    and thereby we have	
    $|M| \leq 2.OPT$.
\end{proof}

\begin{theorem}	\label{thm:upperbound}
    Algorithm \ref{alg:ppl} reaches the final partition while being $(2.k.\ell)$-competitive.
\end{theorem}
\begin{proof}
    The algorithm eventually reaches the final partition since it
     evaluates all possible $\ell$-way partitions of components on each external request,
    including the request that completes revealing of all ground truth components.
    There are at most $(k-1).\ell < k.\ell $ calls to \emph{re-partition()} and by Lemma \ref{lemma:rebalancecost} each costs at most $2.OPT$.
    The total cost is therefore at most $2.OPT.k.\ell$ which implies the competitive ratio.
      \end{proof}

\section{$O(\ell)$-competitive algorithm for $k=3$}


\begin{lemma} \label{lemma:k=3}
  The rebalancing cost for the greedy algorithm for $k=3$ is $O(1)$.
  \maciek{Greedy = find the cheapest (closest to the current) feasible partition}
  \label{rebalancing-cost}
\end{lemma}

\begin{proof} 
% \maciek{Note: we consider a cost of cheapest feasible rebalancing after insertion of one edge. This in contrast to bounding the distance between any two reconfigurations (this theorem does not bound the latter).}
  
  We distinguish among three configuration types of algorithm's clusters: $C_1, C_2, C_3$. In $C_1$ we have $3$ singleton components (this is also the initial configuration of any cluster). In $C_2$ we have one component of size $2$ and one component of size $1$. Finally, in $C_3$ we have one component of size $3$.

  Consider a request $(u, v)$ and let $U, V$ be their clusters.
  If $U=V$, then the request does not require a reconfiguration.
  Now, we consider cases upon the type of clusters $U$ and $V$.
  Note that this is impossible that either $U$ or $V$ is $C_3$ as otherwise the resulting component would have the size $4$, and this contradicts the existence of the perfect partition.
  If either $U$ or $V$ is $C_1$, then either cluster can fit the merged component, and the rebalance is local within $U$ and $V$, for the cost of at most $3$ migrations.

  Now, we focus on the case where both $U$ and $V$ are $C_2$. Note that $(u,v)$ cannot both belong to a component of size $2$, as the merged component would have size $4$.
  If either $u$ or $v$ belongs to a component of size $2$ then it suffices to exchange components of size $1$ between $U$ and $V$.
  Finally, if $u$ and $v$ belong to components of size $1$, then we must place them in a cluster different from $U$ and $V$.
  Note that in such case, a $C_1$-type cluster exists, as otherwise the input graph would not have a perfect partition. The cost of rebalancing is then at most $12$ \maciek{can show smaller constant than 12, but it does not matter that much}.
\end{proof}

\begin{theorem}
  There exists a $O(\ell)$-competitive algorithm for $k=3$.
\end{theorem}

\begin{proof}
  The adversary issues at most $3\ell$ requests, as otherwise the perfect partition would not exist. Each request issues at most one re-balancing for the greedy algorithm, and by Theorem~\ref{rebalancing-cost}, the total cost of any algorithm is $O(k\cdot \ell)$.
\end{proof}

We leverage the simple algorithm $ON_{k=3}$ that seeks a perfect partition for $k=3$,
towards an algorithm for the general online problem.
Note that in the general model,
an optimal partition is not a necessarily a perfect partition.
We divide the sequence of requests into phases.
A phase terminates when there is no perfect partition of components.
We apply requests to $ON_{k=3}$ as before. 
Once the current phase terminates,
we reset all components by removing (forgetting) all revealed edges,
 and then we proceed to the next phase.

\begin{corollary} \label{cor:k=3}
    There exists $O(\ell)$-competitive  algorithm for the general online problem when $k=3$. 
\end{corollary}
\begin{proof}
    Consider any phase and assume it terminates upon arrival of some request $r$.
     By Lemma  \ref{lemma:k=3},
    ON pays $O(\ell)$ during the phase.
    Regardless of the of OPT's partition at the beginning of the phase,
    as long as OPT stays in the same configuration,
     it incurs remote communication cost for at least one request $r'$ (possibly $r'=r$) by the end of the phase.
     Else,
     OPT incurs the cost of moving to new partitions.
     In any case,
     OPT must pay at least one during the phase.
\end{proof}

\section{Corollary and Future Directions}

The gap between upper and lower bound is still substantial, as the best known algorithm is the component-based algorithm of   \cite{repartition-disc} with competitive ratio $O(k^2\ell^2)$.


\section{Todos}

\todo{Make ORCID visible in ACM style}

\todo{Include e-mails}

\todo{Check ACM package whitelist}

\todo{Replace package algorithmpseudocode, it is not whitelisted https://www.acm.org/publications/taps/whitelist-of-latex-packages}

\todo{Make an ACM account for the submission}

\todo{Sum up all the steps needed for the submission}

\todo{ACM keywords are mandatory}

\todo{CCS concepts are mandatory}

\todo{$. \rightarrow \cdot$}

\todo{Font for OPT, ALG, DET, dist etc}

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}  

\begin{appendix}

\section{Ommited results}

\begin{enumerate}
  \item The lower bound of $\Omega(\ell)$ for the scenario with at most $(1/3-1/k)$-augmentation
  \item Costly cascade example (it is easy to present $k^2$ and $k\cdot \sqrt{k}$ (with different approach), and then we can combine these to obtain $k^3$)
  \item $k$-competitive algorithm for the ring communication pattern
  \item $O(\ell)$-competitive algorithm for $k=4$ and $k=5$
\end{enumerate}

\end{appendix}

\end{document}
