\section{An $O(kl)$-competitive Algorithm For the Scenario With the Perfect Partition}

\subsection{On a Cost of a Single Repartition}


\subsubsection{A Costly Repartition Example}

A repartition cost is bounded by $O(kl)$ (cite marcin-chen).
Now we show that the rebalance may be expensive (cubic) in terms of $k$, even for $l$ linear in $k$.

This justifies taking a different approach to repartitioning (see Section PPLA).

\maciek{Possibly simplify $\Omega(k^3)$? Or just present $\Omega(k^2)$?}

\subsubsection{For Constant k, Repartition Cost is Constant?}

\maciek{Interesting research problem: is a single repartition cost bounded by $O(poly(k))$? This would improve currently best-known $O(k^2\ell^2)$ to $O(k\cdot poly(k) \cdot \ell)$, i.e., would tighten the lower bound in terms of $\ell$.}
  \maciek{We have such examples for $k=3,4,5$. It gives us an $O(\ell)$-competitive algorithm for $k=3$}

\begin{theorem}
  The rebalancing cost for the greedy algorithm for $k=3$ is $O(1)$.
  \maciek{Greedy = find the cheapest (closest to the current) feasible partition}
  \label{rebalancing-cost}
\end{theorem}

\begin{proof} 
 \maciek{Note: we consider a cost of cheapest feasible rebalancing after insertion of one edge. This in contrast to bounding the distance between any two reconfigurations (this theorem does not bound the latter).}
  
  We distinguish among three configuration types of algorithm's clusters: $C_1, C_2, C_3$. In $C_1$ we have $3$ singleton components (this is also the initial configuration of any cluster). In $C_2$ we have one component of size $2$ and one component of size $1$. Finally, in $C_3$ we have one component of size $3$.

  Consider a request $(u, v)$ and let $U, V$ be their clusters.
  If $U=V$, then the request does not require a reconfiguration.
  Now, we consider cases upon the type of clusters $U$ and $V$.
  Note that this is impossible that either $U$ or $V$ is $C_3$ as otherwise the resulting component would have the size $4$, and this contradicts the existence of the perfect partition.
  If either $U$ or $V$ is $C_1$, then either cluster can fit the merged component, and the rebalance is local within $U$ and $V$, for the cost of at most $3$ migrations.

  Now, we focus on the case where both $U$ and $V$ are $C_2$. Note that $(u,v)$ cannot both belong to a component of size $2$, as the merged component would have size $4$.
  If either $u$ or $v$ belongs to a component of size $2$ then it suffices to exchange components of size $1$ between $U$ and $V$.
  Finally, if $u$ and $v$ belong to components of size $1$, then we must place them in a cluster different from $U$ and $V$.
  Note that in such case, a $C_1$-type cluster exists, as otherwise the input graph would not have a perfect partition. The cost of rebalancing is then at most $12$ \maciek{can show smaller constant than 12, but it does not matter that much}.
\end{proof}

\begin{theorem}
  There exists a $O(\ell)$-competitive algorithm for $k=3$.
\end{theorem}

\begin{proof}
  The adversary issues at most $3\ell$ requests, as otherwise the perfect partition would not exist. Each request issues at most one rebalancingfor the greedy algorithm, and by Theorem~\ref{rebalancing-cost}, the total cost of any algorithm is $O(k\cdot \ell)$.
\end{proof}



\subsection{Perfect Partition Learner Algorithm}


\maciek{$. \rightarrow \cdot$}
\maciek{Font for OPT, ALG, DET, dist etc}

Let $P_I = I_1, \dots, I_{\ell}$ denote the initial partition with which both ON and OPT begin and
$P_F = F_1, \dots, F_{\ell}$ the final partition.
\begin{definition}	\label{def:dist}
	The \emph{distance} of a partition $P = C_1, \dots, C_{\ell}$ is the number of nodes in $P$ that do not reside in their initial cluster.
	That is,
	$dist(P, P_I) = \sum_{j=1}^{\ell} | C_j \setminus I_j |$. 
\end{definition}

In other words,
at least $dist(P, P_I)/2$ node swaps are required in order to reach the partition $P$ from $P_I$.
Therefore,
$OPT \geq \Delta:= dist(P_F, P_I) $.
We devise an online algorithm that mimics OPT by minimizing the distance to the initial partition $P_I$ with each re-partitioning.
As a result,
ON never ends up in a partition that is further away from $P_I$ than $\Delta$.
This invariant ensures that ON does not pay too much while reaching $P_F$.

\begin{algorithm}
	\renewcommand{\algorithmicrequire}{\textbf{Input:}}
	\renewcommand{\algorithmicensure}{\textbf{Output:}}
	\begin{algorithmic}[1]
		\Require 
		$k, \ell$,
		initial partition $P_I$,
		sequence of  edges $\sigma_1, \dots, \sigma_N$ covering all ground truth components
		\Ensure Final partition $P_F$ 
		\State for each node $v$ create a singleton component $C_v$ and add it to $\mathcal{C}$ \label{line:initcomponents}
		\State on communication request $\sigma_t=\{u,v\}$:
		\State Let $C_1 \ni u$ and $C_2 \ni v$ be the container components
		\If{$C_1 \neq C_2$}
		\State unite the two components into a single component $C'$ and
		$\mathcal{C} = (\mathcal{C}\setminus\set{C_1, C_2}) \cup ~\set{C'}$ \label{line:mergecomponents}
		\If{cluster$(C_1) \neq$ cluster$(C_2)$}		
		\State \textit{re-partition($k, \ell, P_I, \mathcal{C}$)} \label{line:rebalance} 
		\EndIf
		\EndIf
	\end{algorithmic}
	\caption{Perfect Partition Learner}
	\label{alg:ppl}
      \end{algorithm}

      \maciek{``re-partition'' procedure name should indicate the fact that this is a specific repartition that is close to initial configuration}

\begin{property} \label{prop:dist<OPT}
	Let $P$ be any partition chosen by Algorithm \ref{alg:ppl} at Line $\ref{line:rebalance}$.
	Then, $dist(P,P_I) \leq \Delta$.
\end{property}

\begin{lemma}	\label{lemma:rebalancecost}
	The cost of re-partitioning at Line \ref{line:rebalance} is at most $2.OPT$.
\end{lemma}
\begin{IEEEproof}
	Consider the re-partitioning that transforms $P_{t-1}$ to $P_t$ upon the request $\sigma_t$.
	Let $M \subset V$ denote the set of nodes that are migrated during this process.
	We have $M = M^+ \cup M^- \cup M^\circ$,
	where $M^-$ ($M^+$) denotes the subset of nodes that
	enter (leave) their original cluster during the re-partitioning,
	and $M^\circ$ denotes the set of remaining nodes in $M$.
	Since $|M^- \cup M^\circ|$ nodes are not in their original cluster before the re-partitioning,
	by Definition \ref{def:dist},
	the distance before the re-partitioning is $dist(P_{t-1}) \geq | M^- \cup M^\circ |$.
	Analogously,
	 the distance afterwards is $dist(P_{t}) \geq | M^+ \cup M^\circ |$.
	Thus,
	$|M| \leq dist(P_{t-1}) + dist(P_{t})$.
	By Property \ref{prop:dist<OPT},
	$dist(P_{t-1}) , dist(P_{t}) \leq \Delta \leq OPT$
	and thereby we have	
	$|M| \leq 2.OPT$.
\end{IEEEproof}

\begin{theorem}	\label{thm:upperbound}
	Algorithm \ref{alg:ppl} reaches the final partition while being $(2.k.\ell)$-competitive.
\end{theorem}
\begin{IEEEproof}
	The algorithm eventually reaches the final partition since it
	 evaluates all possible $\ell$-way partitioning of components on each external request,
	including the request that completes revealing of all ground truth components.
	There are at most $(k-1).\ell < k.\ell $ calls to \emph{re-partition()} and by Lemma \ref{lemma:rebalancecost} each costs at most $2.OPT$.
	The total cost is therefore at most $2.OPT.k.\ell$ which implies the competitive ratio.
\end{IEEEproof}